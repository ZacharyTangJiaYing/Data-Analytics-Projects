{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Shopee Search and Review Webscraper**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** Zachary Tang <br>\n",
    "**Date published:** 13/1/21 <br>\n",
    "<br>\n",
    "**Contact information:**\n",
    "- Email: zacharytangjiaying@gmail.com\n",
    "- [Github](https://github.com/ZacharyTangJiaYing) \n",
    "- [Linkedin](https://www.linkedin.com/in/zacharytang/)\n",
    "\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **User Guide**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script scrapes search user specified search results in Shopee's website. There are a few options that requires the user's input: \n",
    "\n",
    "1. **Filepath** - specify the filepath where you want to save the scraped results. The results will be saved in .csv format.\n",
    "2. **Country** - choose which Shopee website to scrape based on country.\n",
    "3. **Search term** - user specified search term \n",
    "4. **Pages to scrape** - how many pages of search results to scrape.\n",
    "5. **Scrape within SKU** - option to loop through each listing and pull additional information like seller information, stock information and customer reviews. <span style=\"color:red\">**WARNING:** Might take a long time to finish scraping!</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start scraping, clear the kernel and run all cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for chrome driver\n",
    "options = Options()\n",
    "\n",
    "# options.add_argument('--headless')\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-infobars\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--disable-browser-side-navigation\")\n",
    "options.add_argument(\"--disable-gpu\") \n",
    "options.add_argument('--incognito')\n",
    "options.add_argument(\"start-maximized\")\n",
    "options.add_argument(\"enable-automation\")\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n",
    "\n",
    "# Saved file directory\n",
    "filepath = input('Filepath: ')\n",
    "\n",
    "country = input('SG/MY/TH/ID: ')\n",
    "search = input('Search term: ')\n",
    "scrape_limit = int(input('Pages to scrape: '))\n",
    "scrape_within_SKU = input('Scrape within SKU? Y/N: ')\n",
    "\n",
    "if country == 'SG':\n",
    "    driver.get('https://shopee.sg')\n",
    "if country == 'MY':\n",
    "    driver.get('https://shopee.com.my')\n",
    "if country == 'TH':\n",
    "    driver.get('https://shopee.co.th')\n",
    "if country == 'ID':\n",
    "    driver.get('https://shopee.co.id')\n",
    "    \n",
    "time.sleep(8)\n",
    "    \n",
    "driver.find_element_by_class_name('shopee-searchbar-input__input').send_keys(search, Keys.ENTER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_page(): # scroll down to render all elements in the page\n",
    "    driver.execute_script(\"window.scrollTo(0, 1000)\") \n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollTo(0, 2000)\") \n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollTo(0, 3000)\") \n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollTo(0, 4000)\") \n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollTo(0, 5000)\")\n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollTo(0, 8000)\")\n",
    "    \n",
    "def convert(x): # to remove \"k\" in string and convert string to float\n",
    "    if 'k' in x:\n",
    "        x = float(x.replace('k','')) * 1000\n",
    "        return x\n",
    "    else:\n",
    "        return float(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Execute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scrape_within_SKU == 'Y': \n",
    "    \n",
    "    time.sleep(4)\n",
    "    \n",
    "    driver.find_element_by_xpath('//div[@class=\"shopee-sort-by-options\"]/div[text()=\"Top Sales\"]').click() # navigate to top sales\n",
    "    \n",
    "    time.sleep(4)\n",
    "\n",
    "    page_number = 1\n",
    "    total_pages = int(driver.find_element_by_xpath('//span[@class=\"shopee-mini-page-controller__total\"]').text) # find out the total number of pages\n",
    "    limits = min(scrape_limit, total_pages) # set limits to minimum of specified limit or number of search pages\n",
    "\n",
    "    # initialize variables \n",
    "    urls = []\n",
    "    sold_per_month = []\n",
    "    product_name = []\n",
    "    discounts = []\n",
    "    prices_lowest = []\n",
    "    prices_highest = []\n",
    "    preferred = []\n",
    "    country_ship = []\n",
    "    ad = []\n",
    "\n",
    "    while page_number <= limits: \n",
    "\n",
    "        render_page() # render page\n",
    "\n",
    "        # scrape \n",
    "        \n",
    "        try:\n",
    "            product_name.extend([i.text for i in driver.find_elements_by_xpath('//div[@class=\"_1NoI8_ _2xHE6C _1co5xN\"]')])\n",
    "\n",
    "            sold_per_month.extend([s.text for s in driver.find_elements_by_xpath('//div[@class=\"_245-SC\"]')])\n",
    "\n",
    "            urls.extend([u.get_attribute('href') for u in driver.find_elements_by_xpath('//div[@class=\"col-xs-2-4 shopee-search-item-result__item\"]/div/a')])\n",
    "\n",
    "            number_of_products_in_page = len(driver.find_elements_by_xpath('//div[@class=\"row shopee-search-item-result__items\"]/div'))\n",
    "\n",
    "            # iterate through each element in the search results, since not all listings have the same structure\n",
    "            for i in range(1,(number_of_products_in_page+1)):\n",
    "                \n",
    "                try: # discount tags\n",
    "                    disc_tag = driver.find_element_by_xpath('//div[@class=\"row shopee-search-item-result__items\"]/div[{}]/div/a/div/div[1]/div[2]/div/div/span[1]'.format(i)).text\n",
    "                    discounts.append(disc_tag)\n",
    "                except NoSuchElementException:\n",
    "                    discounts.append(np.nan)\n",
    "\n",
    "                try: # lowest price if there is a price range\n",
    "                    p1 = float(\"\".join([i.text.replace(',','') for i in driver.find_elements_by_xpath('//div[@class=\"row shopee-search-item-result__items\"]/div[{}]/div/a/div/div[2]/div[2]/div[@class=\"_1w9jLI _1DGuEV _2ZYSiu\"]/span'.format(i))][1]))\n",
    "                    prices_lowest.append(p1)\n",
    "                except (NoSuchElementException, IndexError):\n",
    "                    prices_lowest.append(np.nan)\n",
    "\n",
    "                try: # highest price if there is a price range\n",
    "                    p2 = float(\"\".join([i.text for i in driver.find_elements_by_xpath('//div[@class=\"row shopee-search-item-result__items\"]/div[{}]/div/a/div/div[2]/div[2]/div[@class=\"_1w9jLI _1DGuEV _2ZYSiu\"]/span'.format(i))][3]))\n",
    "                    prices_highest.append(p2)\n",
    "                except (NoSuchElementException, IndexError):\n",
    "                    prices_highest.append(np.nan)\n",
    "\n",
    "                try: # preferred seller or not\n",
    "                    pref_tag = driver.find_element_by_xpath('//div[@class=\"row shopee-search-item-result__items\"]/div[{}]/div/a/div/div[1]/div[1]/div/span[@class=\"_1DeDTg\"]'.format(i)).text\n",
    "                    preferred.append(pref_tag)\n",
    "                except NoSuchElementException:\n",
    "                    preferred.append(np.nan)\n",
    "\n",
    "                try: # check if listing is a paid ad\n",
    "                    ad_tag = driver.find_element_by_xpath('//div[@class=\"row shopee-search-item-result__items\"]/div[{}]/div/a/div/div[1]/div[@class=\"_1e9igF\"]/div[@class=\"_2uCaTM\"]'.format(i)).text\n",
    "                    ad.append(ad_tag)\n",
    "                except NoSuchElementException:\n",
    "                    ad.append(np.nan)\n",
    "\n",
    "                try: # check where the item is shipping from\n",
    "                    country_tag = driver.find_element_by_xpath('//div[@class=\"row shopee-search-item-result__items\"]/div[{}]/div/a/div/div[2]/div[@class=\"_41f1_p\"]'.format(i)).text\n",
    "                    if country_tag == '':\n",
    "                        country_ship.append(country)\n",
    "                    else:\n",
    "                        country_ship.append(country_tag)\n",
    "                except NoSuchElementException:\n",
    "                    country_ship.append('np.nan')\n",
    "            \n",
    "            # navigate to the next page\n",
    "            driver.find_element_by_xpath('//button[@class=\"shopee-button-outline shopee-mini-page-controller__next-btn\"]').click()\n",
    "            page_number += 1\n",
    "            time.sleep(3)\n",
    "\n",
    "        except (NoSuchElementException, StaleElementReferenceException, ElementClickInterceptedException): \n",
    "            break  \n",
    "    \n",
    "    # additional information that will be attached to search results \n",
    "    num_sold = []\n",
    "    num_ratings = []\n",
    "    num_fav = []\n",
    "    num_stock = []\n",
    "    seller_name = []\n",
    "    seller_url = []\n",
    "    seller_ratings = []\n",
    "    seller_products = []\n",
    "    seller_response = []\n",
    "    seller_response_time = []\n",
    "    seller_joined = []\n",
    "    seller_follower = []\n",
    "    product_cat = []\n",
    "    product_desc = []\n",
    "    \n",
    "    \n",
    "    # loop through each url in the initial search scrape \n",
    "    for url in urls:\n",
    "    \n",
    "        driver.get(url)\n",
    "        time.sleep(4)\n",
    "    \n",
    "        render_page() # render the page\n",
    "\n",
    "        # get the number of review pages. each page has 6 reviews\n",
    "        rating_list = [convert(i.text[8:-1]) for i in driver.find_elements_by_class_name('product-rating-overview__filter')[1:6]]\n",
    "        number_of_ratings = sum(rating_list)\n",
    "        if number_of_ratings % 6 < 6:\n",
    "            comment_pages = (number_of_ratings - (number_of_ratings % 6)) / 6 + 1\n",
    "        else: comment_pages = number_of_ratings / 6\n",
    "\n",
    "        comment_page_counter = 1\n",
    "\n",
    "        # initialize lists to store the scraped values\n",
    "        filename = driver.find_element_by_xpath('//div[@class=\"qaNIZv\"]/span').text\n",
    "\n",
    "        variation_list = []\n",
    "        date_list = []\n",
    "        username_list = []\n",
    "        comment_list = []\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # gather additional information to be attached to main search results\n",
    "            num_sold.append(convert(driver.find_element_by_class_name('_22sp0A').text))\n",
    "\n",
    "            try:\n",
    "                num_ratings.append(convert(driver.find_element_by_xpath('//div[@class=\"flex _32fuIU\"]/div[2]/div[@class=\"_3Oj5_n\"]').text))\n",
    "            except NoSuchElementException:\n",
    "                num_ratings.append(0)\n",
    "\n",
    "            try:\n",
    "                num_fav.append(driver.find_element_by_xpath('//div[@class=\"flex items-center _25DJo1\"]/div').text)\n",
    "            except NoSuchElementException:\n",
    "                num_fav.append(0)\n",
    "                \n",
    "            num_stock.append(driver.find_element_by_css_selector('#main > div > div._1Bj1VS > div.page-product > \\\n",
    "                                                            div.container > div.product-briefing.flex.card._2cRTS4 > \\\n",
    "                                                            div.flex.flex-auto.k-mj2F > div > div._3DepLY > div > \\\n",
    "                                                            div.flex._3dRJGI._3a2wD- > div > div > div.flex.items-center > \\\n",
    "                                                            div:nth-child(2)').text)\n",
    "\n",
    "            seller_name.append(driver.find_element_by_class_name('_3Lybjn').text)\n",
    "\n",
    "            seller_url.append(driver.find_element_by_class_name('_136nGn').get_attribute('href'))\n",
    "\n",
    "            seller_ratings.append(convert(driver.find_element_by_xpath('//div[@class=\"_3mK1I2\"]/div[1]/div[1]/span').text))\n",
    "\n",
    "            seller_products.append(convert(driver.find_element_by_xpath('//div[@class=\"_3mK1I2\"]/div[1]/a/span').text))\n",
    "\n",
    "            seller_response.append(driver.find_element_by_xpath('//div[@class=\"_3mK1I2\"]/div[2]/div[1]/span').text)\n",
    "\n",
    "            seller_response_time.append(driver.find_element_by_xpath('//div[@class=\"_3mK1I2\"]/div[2]/div[2]/span').text)\n",
    "\n",
    "            seller_joined.append(driver.find_element_by_xpath('//div[@class=\"_3mK1I2\"]/div[3]/div[1]/span').text)\n",
    "\n",
    "            seller_follower.append(convert(driver.find_element_by_xpath('//div[@class=\"_3mK1I2\"]/div[3]/div[2]/span').text))\n",
    "\n",
    "            product_cat.append(\" > \".join([c.text for c in driver.find_elements_by_xpath('//a[@class=\"JFOy4z _20XOUy\"]')]))\n",
    "\n",
    "            product_desc.append(driver.find_element_by_class_name('_2u0jt9').text)\n",
    "        \n",
    "        except (NoSuchElementException, StaleElementReferenceException, ElementClickInterceptedException): \n",
    "            print(\"Error scraping SKU info\")\n",
    "            pass \n",
    "\n",
    "        scrape reviews that will be saved in a seperate csv\n",
    "        while comment_page_counter <= comment_pages:\n",
    "\n",
    "            try:\n",
    "                \n",
    "                for i in driver.find_elements_by_class_name('shopee-product-rating__author-name'):\n",
    "                    username_list.append(i.text)\n",
    "\n",
    "                for c in driver.find_elements_by_class_name('shopee-product-rating__content'):\n",
    "                    comment_list.append(c.text)\n",
    "\n",
    "                for d in driver.find_elements_by_class_name('shopee-product-rating__time'):\n",
    "                    date_list.append(d.text)\n",
    "                    \n",
    "                if not driver.find_elements_by_class_name('shopee-product-rating__variation'):\n",
    "                    variation_list.extend([np.nan for n in range(len(date_list))])               \n",
    "                else: \n",
    "                    for v in driver.find_elements_by_class_name('shopee-product-rating__variation'):\n",
    "                        variation_list.append(v.text)\n",
    "                    \n",
    "                driver.find_elements_by_xpath('//div[@class=\"shopee-page-controller product-ratings__page-controller\"]/button')[-1].click()\n",
    "                comment_page_counter += 1\n",
    "                time.sleep(3)\n",
    "\n",
    "            except (NoSuchElementException, StaleElementReferenceException, ElementClickInterceptedException, IndexError): \n",
    "                comment_page_counter += 1\n",
    "                pass \n",
    "\n",
    "        df = pd.DataFrame(list(zip(date_list, username_list, comment_list, variation_list)), \n",
    "                      columns=[\"date\", \"username\", \"comment\", \"variation\"])\n",
    "\n",
    "        df.to_csv('{0}/{1}.csv'.format(filepath,filename.replace('/', '')), index=False, encoding=\"utf-8_sig\")\n",
    "        print('File for {0} saved! \\n'.format(filename.replace(\"/\", '')))\n",
    "        \n",
    "    df = pd.DataFrame(list(zip(product_name, urls, prices_lowest, prices_highest, discounts, sold_per_month, preferred, country_ship, ad, num_sold, num_ratings, num_fav, num_stock, seller_name, seller_url, seller_products, seller_ratings, seller_response, seller_response_time, seller_joined, seller_follower, product_cat, product_desc)),\n",
    "                      columns=['product_name', 'urls', 'prices_lowest', 'prices_highest', 'discounts', 'sold_per_month', 'preferred', 'country_ship', 'ad', 'num_sold', 'num_ratings', 'num_fav', 'num_stock', 'seller_name', 'seller_url', 'seller_products', 'seller_ratings','seller_response', 'seller_response_time', 'seller_joined', 'seller_follower', 'product_cat', 'product_desc'])\n",
    "\n",
    "    df.to_csv('{0}/scraped.csv'.format(filepath) , index=False, encoding=\"utf-8_sig\")\n",
    "    print('Search results for \"{}\" has been saved! \\n'.format(search))\n",
    "    \n",
    "if scrape_within_SKU == 'N':\n",
    "    \n",
    "    time.sleep(4)\n",
    "    \n",
    "    driver.find_element_by_xpath('//div[@class=\"shopee-sort-by-options\"]/div[text()=\"Top Sales\"]').click() # navigate to top sales\n",
    "    \n",
    "    time.sleep(4)\n",
    "\n",
    "    page_number = 1\n",
    "    total_pages = int(driver.find_element_by_xpath('//span[@class=\"shopee-mini-page-controller__total\"]').text) # find out the total number of pages\n",
    "    limits = min(scrape_limit, total_pages) # set limits to minimum of specified limit or number of search pages\n",
    "\n",
    "    # initialize variables \n",
    "    urls = []\n",
    "    sold_per_month = []\n",
    "    product_name = []\n",
    "    discounts = []\n",
    "    prices_lowest = []\n",
    "    prices_highest = []\n",
    "    preferred = []\n",
    "    country_ship = []\n",
    "    ad = []\n",
    "\n",
    "    while page_number <= limits: \n",
    "\n",
    "        render_page() # render page\n",
    "\n",
    "        # scrape \n",
    "        \n",
    "        try:\n",
    "            product_name.extend([i.text for i in driver.find_elements_by_xpath('//div[@class=\"_1NoI8_ _2xHE6C _1co5xN\"]')])\n",
    "\n",
    "            sold_per_month.extend([s.text for s in driver.find_elements_by_xpath('//div[@class=\"_245-SC\"]')])\n",
    "\n",
    "            urls.extend([u.get_attribute('href') for u in driver.find_elements_by_xpath('//div[@class=\"col-xs-2-4 shopee-search-item-result__item\"]/div/a')])\n",
    "\n",
    "            number_of_products_in_page = len(driver.find_elements_by_xpath('//div[@class=\"row shopee-search-item-result__items\"]/div'))\n",
    "\n",
    "            # iterate through each element in the search results, since not all listings have the same structure\n",
    "            for i in range(1,(number_of_products_in_page+1)):\n",
    "                \n",
    "                try: # discount tags\n",
    "                    disc_tag = driver.find_element_by_xpath('//div[@class=\"row shopee-search-item-result__items\"]/div[{}]/div/a/div/div[1]/div[2]/div/div/span[1]'.format(i)).text\n",
    "                    discounts.append(disc_tag)\n",
    "                except NoSuchElementException:\n",
    "                    discounts.append(np.nan)\n",
    "\n",
    "                try: # lowest price if there is a price range\n",
    "                    p1 = float(\"\".join([i.text.replace(',','') for i in driver.find_elements_by_xpath('//div[@class=\"row shopee-search-item-result__items\"]/div[{}]/div/a/div/div[2]/div[2]/div[@class=\"_1w9jLI _1DGuEV _2ZYSiu\"]/span'.format(i))][1]))\n",
    "                    prices_lowest.append(p1)\n",
    "                except (NoSuchElementException, IndexError):\n",
    "                    prices_lowest.append(np.nan)\n",
    "\n",
    "                try: # highest price if there is a price range\n",
    "                    p2 = float(\"\".join([i.text for i in driver.find_elements_by_xpath('//div[@class=\"row shopee-search-item-result__items\"]/div[{}]/div/a/div/div[2]/div[2]/div[@class=\"_1w9jLI _1DGuEV _2ZYSiu\"]/span'.format(i))][3]))\n",
    "                    prices_highest.append(p2)\n",
    "                except (NoSuchElementException, IndexError):\n",
    "                    prices_highest.append(np.nan)\n",
    "\n",
    "                try: # preferred seller or not\n",
    "                    pref_tag = driver.find_element_by_xpath('//div[@class=\"row shopee-search-item-result__items\"]/div[{}]/div/a/div/div[1]/div[1]/div/span[@class=\"_1DeDTg\"]'.format(i)).text\n",
    "                    preferred.append(pref_tag)\n",
    "                except NoSuchElementException:\n",
    "                    preferred.append(np.nan)\n",
    "\n",
    "                try: # check if listing is a paid ad\n",
    "                    ad_tag = driver.find_element_by_xpath('//div[@class=\"row shopee-search-item-result__items\"]/div[{}]/div/a/div/div[1]/div[@class=\"_1e9igF\"]/div[@class=\"_2uCaTM\"]'.format(i)).text\n",
    "                    ad.append(ad_tag)\n",
    "                except NoSuchElementException:\n",
    "                    ad.append(np.nan)\n",
    "\n",
    "                try: # check where the item is shipping from\n",
    "                    country_tag = driver.find_element_by_xpath('//div[@class=\"row shopee-search-item-result__items\"]/div[{}]/div/a/div/div[2]/div[@class=\"_41f1_p\"]'.format(i)).text\n",
    "                    if country_tag == '':\n",
    "                        country_ship.append(country)\n",
    "                    else:\n",
    "                        country_ship.append(country_tag)\n",
    "                except NoSuchElementException:\n",
    "                    country_ship.append('np.nan')\n",
    "            \n",
    "            # navigate to the next page\n",
    "            driver.find_element_by_xpath('//button[@class=\"shopee-button-outline shopee-mini-page-controller__next-btn\"]').click()\n",
    "            page_number += 1\n",
    "            time.sleep(3)\n",
    "\n",
    "        except (NoSuchElementException, StaleElementReferenceException, ElementClickInterceptedException): \n",
    "            break \n",
    "\n",
    "    # save the results \n",
    "    df = pd.DataFrame(list(zip(product_name, urls, prices_lowest, prices_highest, discounts, sold_per_month, preferred, country_ship, ad)),\n",
    "                 columns=['product_name', 'urls', 'prices_lowest', 'prices_highest', 'discounts', 'sold_per_month', 'preferred', 'country_ship', 'ad'])\n",
    "\n",
    "    df.to_csv('{0}/search_scraped.csv'.format(filepath) , index=False, encoding=\"utf-8_sig\")\n",
    "    print('Search results for \"{}\" has been saved! \\n'.format(search))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
